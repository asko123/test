{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Document Chat Bot\n",
        "\n",
        "This notebook demonstrates a multi-document chatbot for querying PDF documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install goldmansachs.awm_genai -U\n",
        "%pip install python-dotenv pandas ipywidgets pdfplumber\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from goldmansachs.awm_genai import LLM, LLMConfig\n",
        "import os\n",
        "from typing import List, Dict\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "import pdfplumber\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "app_id = \"trai\"\n",
        "env = \"uat\"\n",
        "\n",
        "# Model Configuration - Choose your model\n",
        "available_models = [\"gemini-2.5-pro\", \"gemini-2.5-flash-lite\"]\n",
        "\n",
        "# Create model selection widget\n",
        "model_selector = widgets.Dropdown(\n",
        "    options=available_models,\n",
        "    value=\"gemini-2.5-flash-lite\",\n",
        "    description='Model:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Display model selector\n",
        "display(HTML(\"<h3>Select Model</h3>\"))\n",
        "display(HTML(\"<p><b>gemini-2.5-pro:</b> More capable, better for complex questions<br><b>gemini-2.5-flash-lite:</b> Faster responses, good for simple queries</p>\"))\n",
        "display(model_selector)\n",
        "\n",
        "# Store configuration\n",
        "temperature = 0\n",
        "log_level = \"DEBUG\"\n",
        "\n",
        "print(f\"\\nApp ID: {app_id}\")\n",
        "print(f\"Environment: {env}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM with selected model\n",
        "model_name = model_selector.value\n",
        "\n",
        "llm_config = LLMConfig(\n",
        "    app_id=app_id,\n",
        "    env=env,\n",
        "    model_name=model_name,\n",
        "    temperature=temperature,\n",
        "    log_level=log_level,\n",
        ")\n",
        "\n",
        "llm = LLM.init(config=llm_config)\n",
        "print(f\"‚úÖ LLM initialized successfully with {model_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Upload Documents\n",
        "\n",
        "Use the file upload widget below to select your PDF documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create file upload widget\n",
        "upload_widget = widgets.FileUpload(\n",
        "    accept='.pdf',\n",
        "    multiple=True,\n",
        "    description='Select PDFs'\n",
        ")\n",
        "\n",
        "# Create process button\n",
        "process_button = widgets.Button(\n",
        "    description='Extract Text',\n",
        "    button_style='primary',\n",
        "    icon='check'\n",
        ")\n",
        "\n",
        "# Create output widget for status messages\n",
        "output = widgets.Output()\n",
        "\n",
        "# Store extracted text globally\n",
        "extracted_text = None\n",
        "document_names = []\n",
        "\n",
        "def on_process_button_clicked(b):\n",
        "    global extracted_text, document_names\n",
        "    \n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        \n",
        "        if not upload_widget.value:\n",
        "            print(\"‚ö†Ô∏è Please select PDF files first\")\n",
        "            return\n",
        "        \n",
        "        try:\n",
        "            all_text = []\n",
        "            document_names = []\n",
        "            \n",
        "            # Extract text from uploaded files\n",
        "            files = upload_widget.value\n",
        "            print(f\"Extracting text from {len(files)} files...\\n\")\n",
        "            \n",
        "            for file_info in files:\n",
        "                filename = file_info['name']\n",
        "                content = file_info['content']\n",
        "                document_names.append(filename)\n",
        "                \n",
        "                # Save to temp file\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:\n",
        "                    tmp_file.write(content)\n",
        "                    tmp_path = tmp_file.name\n",
        "                \n",
        "                try:\n",
        "                    # Extract text using pdfplumber\n",
        "                    with pdfplumber.open(tmp_path) as pdf:\n",
        "                        doc_text = f\"\\n\\n--- Document: {filename} ---\\n\\n\"\n",
        "                        for page_num, page in enumerate(pdf.pages, 1):\n",
        "                            text = page.extract_text()\n",
        "                            if text:\n",
        "                                doc_text += f\"\\n[Page {page_num}]\\n{text}\\n\"\n",
        "                        all_text.append(doc_text)\n",
        "                        print(f\"  ‚úì {filename} - {len(pdf.pages)} pages extracted\")\n",
        "                finally:\n",
        "                    os.unlink(tmp_path)\n",
        "            \n",
        "            # Combine all extracted text\n",
        "            extracted_text = \"\\n\\n\".join(all_text)\n",
        "            \n",
        "            print(f\"\\n‚úÖ Successfully extracted text from {len(files)} documents\")\n",
        "            print(f\"Total characters: {len(extracted_text):,}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "process_button.on_click(on_process_button_clicked)\n",
        "\n",
        "# Display widgets\n",
        "display(HTML(\"<h3>üìÅ Upload and Extract PDF Documents</h3>\"))\n",
        "display(upload_widget)\n",
        "display(process_button)\n",
        "display(output)\n",
        "\n",
        "print(\"üëÜ Use the widget above to select PDFs and extract their text\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Ask Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if text is extracted\n",
        "if extracted_text is None:\n",
        "    print(\"‚ö†Ô∏è Please extract text from PDFs first (see section 4)\")\n",
        "else:\n",
        "    # Function to ask questions\n",
        "    def ask_question(question: str) -> str:\n",
        "        \"\"\"Ask a question about the documents.\"\"\"\n",
        "        # Create prompt with context\n",
        "        full_prompt = f\"\"\"Based on the following document content, please answer the question.\n",
        "\n",
        "Document Content:\n",
        "{extracted_text}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Please provide a detailed answer based only on the information in the documents above. If the information is not in the documents, please say so.\"\"\"\n",
        "        \n",
        "        # Get response\n",
        "        response = llm.invoke(full_prompt)\n",
        "        return response\n",
        "    \n",
        "    print(\"‚úÖ Ready to answer questions!\")\n",
        "    print(f\"Documents loaded: {', '.join(document_names)}\")\n",
        "    print(\"\\nUse ask_question('your question') to ask questions.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Example Question\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if everything is ready\n",
        "if extracted_text is None:\n",
        "    print(\"‚ö†Ô∏è Please extract text from PDFs first (see section 4)\")\n",
        "elif 'ask_question' not in globals():\n",
        "    print(\"‚ö†Ô∏è Please run section 5 first\")\n",
        "else:\n",
        "    # Ask a question about the documents\n",
        "    question = \"What are the key findings in the documents?\"\n",
        "    \n",
        "    print(f\"Question: {question}\\n\")\n",
        "    print(\"Generating response...\\n\")\n",
        "    \n",
        "    response = ask_question(question)\n",
        "    \n",
        "    print(\"Response:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(response)\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Interactive Chat Interface\n",
        "\n",
        "Chat with your documents interactively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if everything is ready\n",
        "if extracted_text is None:\n",
        "    print(\"‚ö†Ô∏è Please extract text from PDFs first (see section 4)\")\n",
        "else:\n",
        "    # Chat history\n",
        "    chat_history = []\n",
        "    \n",
        "    def chat_with_documents(question: str) -> str:\n",
        "        \"\"\"Send a question to the LLM and get a response with chat history.\"\"\"\n",
        "        response = ask_question(question)\n",
        "        \n",
        "        # Store in chat history\n",
        "        chat_history.append({\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"question\": question,\n",
        "            \"response\": response\n",
        "        })\n",
        "        \n",
        "        return response\n",
        "    \n",
        "    print(\"‚úÖ Chat interface ready!\")\n",
        "    print(\"\\nUse chat_with_documents('your question') to ask questions.\")\n",
        "    print(\"\\nExample:\")\n",
        "    print(\"  chat_with_documents('What are the key findings?')\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Example: Ask Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Ask your first question\n",
        "if 'chat_with_documents' in globals():\n",
        "    response = chat_with_documents(\"What are the main topics in the documents?\")\n",
        "    print(response)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Please complete the setup first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. View Chat History\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display chat history as a DataFrame\n",
        "if 'chat_history' in globals() and chat_history:\n",
        "    df_history = pd.DataFrame(chat_history)\n",
        "    display(df_history)\n",
        "else:\n",
        "    print(\"No chat history yet. Start asking questions!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
