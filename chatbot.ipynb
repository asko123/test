{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Document Chat Bot\n",
        "\n",
        "This notebook demonstrates a multi-document chatbot for querying PDF documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install goldmansachs.awm_genai -U\n",
        "%pip install python-dotenv pandas ipywidgets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from goldmansachs.awm_genai import DocUtils, LLM, LLMConfig\n",
        "import os\n",
        "from typing import List, Dict\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "app_id = \"trai\"\n",
        "env = \"uat\"\n",
        "\n",
        "# Model Configuration\n",
        "model_name = \"gemini-2.0-flash\"\n",
        "temperature = 0\n",
        "log_level = \"DEBUG\"\n",
        "\n",
        "print(f\"App ID: {app_id}\")\n",
        "print(f\"Environment: {env}\")\n",
        "print(f\"Model: {model_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Document Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Document Utilities\n",
        "doc_utils = DocUtils(app_id=app_id, env=env)\n",
        "print(\"Document utilities initialized successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Upload Documents\n",
        "\n",
        "Use the file upload widget below to select your PDF documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create file upload widget\n",
        "upload_widget = widgets.FileUpload(\n",
        "    accept='.pdf',\n",
        "    multiple=True,\n",
        "    description='Select PDFs'\n",
        ")\n",
        "\n",
        "# Create upload button\n",
        "upload_button = widgets.Button(\n",
        "    description='Upload Documents',\n",
        "    button_style='primary',\n",
        "    icon='upload'\n",
        ")\n",
        "\n",
        "# Create output widget for status messages\n",
        "output = widgets.Output()\n",
        "\n",
        "# Store uploaded documents globally\n",
        "uploaded_documents = None\n",
        "temp_file_paths = []\n",
        "\n",
        "def on_upload_button_clicked(b):\n",
        "    global uploaded_documents, temp_file_paths\n",
        "    \n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        \n",
        "        if not upload_widget.value:\n",
        "            print(\"‚ö†Ô∏è Please select PDF files first\")\n",
        "            return\n",
        "        \n",
        "        try:\n",
        "            # Clear previous temp files\n",
        "            for temp_path in temp_file_paths:\n",
        "                if os.path.exists(temp_path):\n",
        "                    os.unlink(temp_path)\n",
        "            temp_file_paths = []\n",
        "            \n",
        "            # Save uploaded files to temp directory\n",
        "            files = upload_widget.value\n",
        "            print(f\"Processing {len(files)} files...\")\n",
        "            \n",
        "            for file_info in files:\n",
        "                # file_info is a Bunch object with 'name' and 'content' attributes\n",
        "                filename = file_info['name']\n",
        "                content = file_info['content']\n",
        "                \n",
        "                # Create temp file\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:\n",
        "                    tmp_file.write(content)\n",
        "                    temp_file_paths.append(tmp_file.name)\n",
        "                    print(f\"  ‚úì {filename}\")\n",
        "            \n",
        "            # Upload to system\n",
        "            print(\"\\nUploading documents to system...\")\n",
        "            uploaded_documents = doc_utils.upload(file_paths=temp_file_paths)\n",
        "            \n",
        "            print(f\"\\n‚úÖ Successfully uploaded {len(uploaded_documents)} documents\")\n",
        "            print(\"\\nDocument Details:\")\n",
        "            for i, doc in enumerate(uploaded_documents, 1):\n",
        "                print(f\"  {i}. {doc}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "upload_button.on_click(on_upload_button_clicked)\n",
        "\n",
        "# Display widgets\n",
        "display(HTML(\"<h3>üìÅ Upload PDF Documents</h3>\"))\n",
        "display(upload_widget)\n",
        "display(upload_button)\n",
        "display(output)\n",
        "\n",
        "print(\"üëÜ Use the widget above to select and upload your PDF documents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialize LLM with Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if documents are uploaded\n",
        "if uploaded_documents is None:\n",
        "    print(\"‚ö†Ô∏è Please upload documents first using the widget above\")\n",
        "else:\n",
        "    # Define LLM configuration\n",
        "    llm_config = LLMConfig(\n",
        "        app_id=app_id,\n",
        "        env=env,\n",
        "        model_name=model_name,\n",
        "        temperature=temperature,\n",
        "        log_level=log_level,\n",
        "    )\n",
        "    \n",
        "    # Initialize LLM\n",
        "    llm = LLM.init(config=llm_config)\n",
        "    print(\"‚úÖ LLM initialized successfully\")\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Temperature: {temperature}\")\n",
        "    \n",
        "    # Use uploaded documents\n",
        "    documents = uploaded_documents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Query Documents - Single Question\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if documents and LLM are ready\n",
        "if uploaded_documents is None:\n",
        "    print(\"‚ö†Ô∏è Please upload documents first (see section 4)\")\n",
        "elif 'llm' not in globals():\n",
        "    print(\"‚ö†Ô∏è Please initialize LLM first (see section 5)\")\n",
        "else:\n",
        "    # Ask a question about the documents\n",
        "    question = \"Write a summary about the documents.\"\n",
        "    \n",
        "    print(f\"Question: {question}\\n\")\n",
        "    print(\"Generating response...\\n\")\n",
        "    \n",
        "    response = llm.invoke(\n",
        "        question,\n",
        "        documents=documents,\n",
        "    )\n",
        "    \n",
        "    print(\"Response:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(response)\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Interactive Chat Interface\n",
        "\n",
        "Chat with your documents interactively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if everything is ready\n",
        "if uploaded_documents is None:\n",
        "    print(\"‚ö†Ô∏è Please upload documents first (see section 4)\")\n",
        "elif 'llm' not in globals():\n",
        "    print(\"‚ö†Ô∏è Please initialize LLM first (see section 5)\")\n",
        "else:\n",
        "    # Chat history\n",
        "    chat_history = []\n",
        "    \n",
        "    def chat_with_documents(question: str) -> str:\n",
        "        \"\"\"Send a question to the LLM and get a response.\"\"\"\n",
        "        response = llm.invoke(\n",
        "            question,\n",
        "            documents=documents,\n",
        "        )\n",
        "        \n",
        "        # Store in chat history\n",
        "        chat_history.append({\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"question\": question,\n",
        "            \"response\": response\n",
        "        })\n",
        "        \n",
        "        return response\n",
        "    \n",
        "    print(\"‚úÖ Chat interface ready!\")\n",
        "    print(\"\\nUse chat_with_documents('your question') to ask questions.\")\n",
        "    print(\"\\nExample:\")\n",
        "    print(\"  chat_with_documents('What are the key findings?')\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Example: Ask Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Ask your first question\n",
        "if 'chat_with_documents' in globals():\n",
        "    response = chat_with_documents(\"What are the key findings in the documents?\")\n",
        "    print(response)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Please complete the setup first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. View Chat History\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display chat history as a DataFrame\n",
        "if 'chat_history' in globals() and chat_history:\n",
        "    df_history = pd.DataFrame(chat_history)\n",
        "    display(df_history)\n",
        "else:\n",
        "    print(\"No chat history yet. Start asking questions!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
