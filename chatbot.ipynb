{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Document Chat Bot\n",
        "\n",
        "This notebook demonstrates a multi-document chatbot for querying PDF documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install goldmansachs.awm_genai -U\n",
        "%pip install python-dotenv pandas ipywidgets pdfplumber\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from goldmansachs.awm_genai import LLM, LLMConfig\n",
        "import os\n",
        "from typing import List, Dict\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "import pdfplumber\n",
        "import json\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "app_id = \"trai\"\n",
        "env = \"uat\"\n",
        "\n",
        "# Model Configuration - Choose your model\n",
        "available_models = [\"gemini-2.5-pro\", \"gemini-2.5-flash-lite\"]\n",
        "\n",
        "# Create model selection widget\n",
        "model_selector = widgets.Dropdown(\n",
        "    options=available_models,\n",
        "    value=\"gemini-2.5-flash-lite\",\n",
        "    description='Model:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Display model selector\n",
        "display(HTML(\"<h3>Select Model</h3>\"))\n",
        "display(HTML(\"<p><b>gemini-2.5-pro:</b> More capable, better for complex questions<br><b>gemini-2.5-flash-lite:</b> Faster responses, good for simple queries</p>\"))\n",
        "display(model_selector)\n",
        "\n",
        "# Store configuration\n",
        "temperature = 0\n",
        "log_level = \"DEBUG\"\n",
        "\n",
        "print(f\"\\nApp ID: {app_id}\")\n",
        "print(f\"Environment: {env}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM with selected model\n",
        "model_name = model_selector.value\n",
        "\n",
        "llm_config = LLMConfig(\n",
        "    app_id=app_id,\n",
        "    env=env,\n",
        "    model_name=model_name,\n",
        "    temperature=temperature,\n",
        "    log_level=log_level,\n",
        ")\n",
        "\n",
        "llm = LLM.init(config=llm_config)\n",
        "print(f\"[SUCCESS] LLM initialized successfully with {model_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Upload Documents\n",
        "\n",
        "Use the file upload widget below to select your PDF documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to extract PDF content with tables and JSON\n",
        "def extract_pdf_content(file_path: str, filename: str) -> str:\n",
        "    \"\"\"Extract text, tables, and JSON from PDF.\"\"\"\n",
        "    content_parts = [f\"\\n\\n{'='*80}\\nDocument: {filename}\\n{'='*80}\\n\"]\n",
        "    \n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages, 1):\n",
        "            content_parts.append(f\"\\n[Page {page_num}]\\n\")\n",
        "            \n",
        "            # Extract tables on this page\n",
        "            tables = page.extract_tables()\n",
        "            \n",
        "            # Get bounding boxes of tables to exclude from text\n",
        "            table_bboxes = []\n",
        "            if tables:\n",
        "                for table in page.find_tables():\n",
        "                    table_bboxes.append(table.bbox)\n",
        "            \n",
        "            # Extract text excluding table areas\n",
        "            if table_bboxes:\n",
        "                text = page.filter(lambda obj: not any(\n",
        "                    obj.get('x0', 0) >= bbox[0] and obj.get('x1', 0) <= bbox[2] and\n",
        "                    obj.get('top', 0) >= bbox[1] and obj.get('bottom', 0) <= bbox[3]\n",
        "                    for bbox in table_bboxes\n",
        "                )).extract_text()\n",
        "            else:\n",
        "                text = page.extract_text()\n",
        "            \n",
        "            # Check for JSON/JSONL content in text\n",
        "            if text and text.strip():\n",
        "                json_objects = extract_json_content(text)\n",
        "                \n",
        "                if json_objects:\n",
        "                    # Add regular text (non-JSON parts)\n",
        "                    non_json_text = remove_json_from_text(text)\n",
        "                    if non_json_text.strip():\n",
        "                        content_parts.append(f\"{non_json_text}\\n\")\n",
        "                    \n",
        "                    # Add formatted JSON objects\n",
        "                    for json_idx, json_obj in enumerate(json_objects, 1):\n",
        "                        formatted_json = format_json_object(json_obj, page_num, json_idx, filename)\n",
        "                        content_parts.append(f\"\\n{formatted_json}\\n\")\n",
        "                else:\n",
        "                    # No JSON, add as regular text\n",
        "                    content_parts.append(f\"{text}\\n\")\n",
        "            \n",
        "            # Add tables with proper formatting\n",
        "            if tables:\n",
        "                for table_idx, table in enumerate(tables, 1):\n",
        "                    if table and len(table) > 0:\n",
        "                        formatted_table = format_table(table, page_num, table_idx, filename)\n",
        "                        content_parts.append(f\"\\n{formatted_table}\\n\")\n",
        "    \n",
        "    return \"\\n\".join(content_parts)\n",
        "\n",
        "def extract_json_content(text: str) -> list:\n",
        "    \"\"\"Extract JSON or JSONL objects from text.\"\"\"\n",
        "    json_objects = []\n",
        "    \n",
        "    # Try to find JSON objects\n",
        "    json_pattern = r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}'\n",
        "    matches = re.finditer(json_pattern, text, re.DOTALL)\n",
        "    \n",
        "    for match in matches:\n",
        "        try:\n",
        "            json_str = match.group(0)\n",
        "            json_obj = json.loads(json_str)\n",
        "            json_objects.append(json_obj)\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "    \n",
        "    # Also try line-by-line for JSONL format\n",
        "    lines = text.split('\\n')\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line.startswith('{') and line.endswith('}'):\n",
        "            try:\n",
        "                json_obj = json.loads(line)\n",
        "                if json_obj not in json_objects:\n",
        "                    json_objects.append(json_obj)\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    return json_objects\n",
        "\n",
        "def remove_json_from_text(text: str) -> str:\n",
        "    \"\"\"Remove JSON objects from text to get only regular text.\"\"\"\n",
        "    json_pattern = r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}'\n",
        "    cleaned_text = re.sub(json_pattern, '', text, flags=re.DOTALL)\n",
        "    return cleaned_text\n",
        "\n",
        "def format_json_object(json_obj: dict, page_num: int, json_idx: int, filename: str) -> str:\n",
        "    \"\"\"Format JSON object for LLM understanding.\"\"\"\n",
        "    json_parts = []\n",
        "    json_parts.append(f\"--- JSON OBJECT {json_idx} (Document: {filename}, Page {page_num}) ---\")\n",
        "    \n",
        "    # Add formatted key-value pairs\n",
        "    json_parts.append(\"\\nStructured Data Fields:\")\n",
        "    for key, value in json_obj.items():\n",
        "        # Clean up the value\n",
        "        if isinstance(value, str):\n",
        "            value = ' '.join(value.split())\n",
        "        json_parts.append(f\"  {key}: {value}\")\n",
        "    \n",
        "    # Add JSON format\n",
        "    json_parts.append(\"\\nJSON Format:\")\n",
        "    json_parts.append(json.dumps(json_obj, indent=2))\n",
        "    \n",
        "    json_parts.append(f\"--- END JSON OBJECT {json_idx} ---\\n\")\n",
        "    \n",
        "    return \"\\n\".join(json_parts)\n",
        "\n",
        "def format_table(table: list, page_num: int, table_idx: int, filename: str) -> str:\n",
        "    \"\"\"Format table with proper structure.\"\"\"\n",
        "    if not table or len(table) == 0:\n",
        "        return \"\"\n",
        "    \n",
        "    # Clean table data\n",
        "    cleaned_table = []\n",
        "    for row in table:\n",
        "        cleaned_row = [str(cell).strip() if cell is not None else \"\" for cell in row]\n",
        "        if any(cleaned_row):\n",
        "            cleaned_table.append(cleaned_row)\n",
        "    \n",
        "    if not cleaned_table:\n",
        "        return \"\"\n",
        "    \n",
        "    table_parts = []\n",
        "    table_parts.append(f\"--- TABLE {table_idx} (Document: {filename}, Page {page_num}) ---\")\n",
        "    \n",
        "    # Assume first row is header\n",
        "    headers = cleaned_table[0]\n",
        "    data_rows = cleaned_table[1:]\n",
        "    \n",
        "    # Add headers\n",
        "    table_parts.append(\"\\nColumn Headers:\")\n",
        "    table_parts.append(\" | \".join(headers))\n",
        "    table_parts.append(\"-\" * 80)\n",
        "    \n",
        "    # Add data rows\n",
        "    table_parts.append(\"\\nTable Data:\")\n",
        "    for row in data_rows:\n",
        "        table_parts.append(\" | \".join(row))\n",
        "    \n",
        "    # Add markdown format for better LLM understanding\n",
        "    table_parts.append(\"\\nMarkdown Format:\")\n",
        "    table_parts.append(\"| \" + \" | \".join(headers) + \" |\")\n",
        "    table_parts.append(\"|\" + \"|\".join([\"---\" for _ in headers]) + \"|\")\n",
        "    for row in data_rows:\n",
        "        table_parts.append(\"| \" + \" | \".join(row) + \" |\")\n",
        "    \n",
        "    table_parts.append(f\"--- END TABLE {table_idx} ---\\n\")\n",
        "    \n",
        "    return \"\\n\".join(table_parts)\n",
        "\n",
        "# Helper functions for JSON extraction\n",
        "def extract_from_json_file(file_path: str, filename: str) -> str:\n",
        "    \"\"\"Extract and format JSON file content.\"\"\"\n",
        "    content_parts = [f\"\\n\\n{'='*80}\\nDocument: {filename}\\n{'='*80}\\n\"]\n",
        "    \n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        \n",
        "        if isinstance(data, list):\n",
        "            content_parts.append(\"\\nThis file contains a list of JSON objects:\\n\")\n",
        "            for idx, obj in enumerate(data, 1):\n",
        "                formatted = format_json_object(obj, 0, idx, filename)\n",
        "                content_parts.append(f\"\\n{formatted}\\n\")\n",
        "        elif isinstance(data, dict):\n",
        "            formatted = format_json_object(data, 0, 1, filename)\n",
        "            content_parts.append(f\"\\n{formatted}\\n\")\n",
        "        else:\n",
        "            content_parts.append(f\"\\nJSON Value: {data}\\n\")\n",
        "    except Exception as e:\n",
        "        content_parts.append(f\"\\n[ERROR] Failed to parse JSON: {str(e)}\\n\")\n",
        "    \n",
        "    return \"\\n\".join(content_parts)\n",
        "\n",
        "def extract_from_jsonl_file(file_path: str, filename: str) -> str:\n",
        "    \"\"\"Extract and format JSONL file content.\"\"\"\n",
        "    content_parts = [f\"\\n\\n{'='*80}\\nDocument: {filename}\\n{'='*80}\\n\"]\n",
        "    content_parts.append(\"\\nThis file contains multiple JSON objects (one per line):\\n\")\n",
        "    \n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            for idx, line in enumerate(f, 1):\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    try:\n",
        "                        obj = json.loads(line)\n",
        "                        formatted = format_json_object(obj, 0, idx, filename)\n",
        "                        content_parts.append(f\"\\n{formatted}\\n\")\n",
        "                    except json.JSONDecodeError:\n",
        "                        content_parts.append(f\"\\n[Line {idx}] Invalid JSON: {line[:100]}...\\n\")\n",
        "    except Exception as e:\n",
        "        content_parts.append(f\"\\n[ERROR] Failed to parse JSONL: {str(e)}\\n\")\n",
        "    \n",
        "    return \"\\n\".join(content_parts)\n",
        "\n",
        "# Create file upload widget\n",
        "upload_widget = widgets.FileUpload(\n",
        "    accept='.pdf,.json,.jsonl,.txt',\n",
        "    multiple=True,\n",
        "    description='Select Files'\n",
        ")\n",
        "\n",
        "# Create process button\n",
        "process_button = widgets.Button(\n",
        "    description='Extract Text',\n",
        "    button_style='primary',\n",
        "    icon='check'\n",
        ")\n",
        "\n",
        "# Create output widget for status messages\n",
        "output = widgets.Output()\n",
        "\n",
        "# Store extracted text globally\n",
        "extracted_text = None\n",
        "document_names = []\n",
        "\n",
        "def on_process_button_clicked(b):\n",
        "    global extracted_text, document_names\n",
        "    \n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        \n",
        "        if not upload_widget.value:\n",
        "            print(\"[WARNING] Please select PDF files first\")\n",
        "            return\n",
        "        \n",
        "        try:\n",
        "            all_text = []\n",
        "            document_names = []\n",
        "            \n",
        "            # Extract content from uploaded files\n",
        "            files = upload_widget.value\n",
        "            print(f\"Processing {len(files)} files...\\n\")\n",
        "            \n",
        "            temp_files = []\n",
        "            document_names = []\n",
        "            \n",
        "            # Save uploaded files temporarily\n",
        "            for file_info in files:\n",
        "                filename = file_info['name']\n",
        "                content = file_info['content']\n",
        "                document_names.append(filename)\n",
        "                \n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:\n",
        "                    tmp_file.write(content)\n",
        "                    temp_files.append((tmp_file.name, filename))\n",
        "            \n",
        "            # Extract content based on file type\n",
        "            for tmp_path, filename in temp_files:\n",
        "                try:\n",
        "                    file_ext = filename.split('.')[-1].lower()\n",
        "                    \n",
        "                    if file_ext == 'pdf':\n",
        "                        doc_content = extract_pdf_content(tmp_path, filename)\n",
        "                    elif file_ext == 'json':\n",
        "                        doc_content = extract_from_json_file(tmp_path, filename)\n",
        "                    elif file_ext == 'jsonl':\n",
        "                        doc_content = extract_from_jsonl_file(tmp_path, filename)\n",
        "                    elif file_ext == 'txt':\n",
        "                        # Extract from text file\n",
        "                        with open(tmp_path, 'r', encoding='utf-8') as f:\n",
        "                            text_content = f.read()\n",
        "                        doc_content = f\"\\n\\n{'='*80}\\nDocument: {filename}\\n{'='*80}\\n\\n{text_content}\\n\"\n",
        "                    else:\n",
        "                        doc_content = f\"\\n[ERROR] Unsupported file type: {file_ext}\\n\"\n",
        "                    \n",
        "                    all_text.append(doc_content)\n",
        "                    print(f\"  [OK] {filename} - extracted successfully\")\n",
        "                finally:\n",
        "                    os.unlink(tmp_path)\n",
        "            \n",
        "            # Combine all extracted text\n",
        "            extracted_text = \"\\n\\n\".join(all_text)\n",
        "            \n",
        "            print(f\"\\n[SUCCESS] Successfully extracted text from {len(files)} documents\")\n",
        "            print(f\"Total characters: {len(extracted_text):,}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Error: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "process_button.on_click(on_process_button_clicked)\n",
        "\n",
        "# Display widgets\n",
        "display(HTML(\"<h3>Upload and Extract Documents</h3>\"))\n",
        "display(HTML(\"<p>Supported formats: PDF, JSON, JSONL, TXT</p>\"))\n",
        "display(upload_widget)\n",
        "display(process_button)\n",
        "display(output)\n",
        "\n",
        "print(\"Use the widget above to select files (PDF, JSON, JSONL, or TXT) and extract their content\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Ask Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if text is extracted\n",
        "if extracted_text is None:\n",
        "    print(\"[WARNING] Please extract text from PDFs first (see section 4)\")\n",
        "else:\n",
        "    # Function to ask questions\n",
        "    def ask_question(question: str) -> str:\n",
        "        \"\"\"Ask a question about the documents.\"\"\"\n",
        "        # Create prompt with context\n",
        "        full_prompt = f\"\"\"You are a helpful assistant that answers questions based on provided documents.\n",
        "\n",
        "The documents may contain:\n",
        "- Regular text content\n",
        "- Tables with headers and data rows\n",
        "- Structured JSON objects with field-value pairs\n",
        "- JSONL data (multiple JSON objects)\n",
        "\n",
        "Document Content:\n",
        "{extracted_text}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Instructions:\n",
        "1. Provide a clear, concise answer based ONLY on the information in the documents\n",
        "2. Format your response for readability with bullet points and clear paragraphs\n",
        "3. When referencing data, cite the source (e.g., \"from Table 1 on Page 3\" or \"JSON Object 2\")\n",
        "4. If information comes from JSON fields, mention the field names\n",
        "5. If the information is not in the documents, clearly state that\n",
        "6. Do not include raw JSON dumps - summarize the information\n",
        "\n",
        "Answer:\"\"\"\n",
        "        \n",
        "        # Get response\n",
        "        response = llm.invoke(full_prompt)\n",
        "        \n",
        "        # Extract actual content from response\n",
        "        actual_response = None\n",
        "        \n",
        "        # Try different response formats\n",
        "        if hasattr(response, 'content'):\n",
        "            # Response object with content attribute\n",
        "            actual_response = response.content\n",
        "        elif isinstance(response, dict):\n",
        "            # Handle SDK response format\n",
        "            if 'Response' in response and 'content' in response['Response']:\n",
        "                actual_response = response['Response']['content']\n",
        "            elif 'content' in response:\n",
        "                actual_response = response['content']\n",
        "            else:\n",
        "                actual_response = str(response)\n",
        "        else:\n",
        "            actual_response = str(response)\n",
        "        \n",
        "        # Clean up the response - remove escape sequences\n",
        "        if actual_response:\n",
        "            actual_response = actual_response.replace('\\\\n\\\\n', '\\n\\n')\n",
        "            actual_response = actual_response.replace('\\\\n', '\\n')\n",
        "            actual_response = actual_response.strip()\n",
        "        \n",
        "        return actual_response\n",
        "    \n",
        "    print(\"[SUCCESS] Ready to answer questions!\")\n",
        "    print(f\"Documents loaded: {', '.join(document_names)}\")\n",
        "    print(\"\\nUse ask_question('your question') to ask questions.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Example Question\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if everything is ready\n",
        "if extracted_text is None:\n",
        "    print(\"[WARNING] Please extract text from PDFs first (see section 4)\")\n",
        "elif 'ask_question' not in globals():\n",
        "    print(\"[WARNING] Please run section 5 first\")\n",
        "else:\n",
        "    # Ask a question about the documents\n",
        "    question = \"What are the key findings in the documents?\"\n",
        "    \n",
        "    print(f\"Question: {question}\\n\")\n",
        "    print(\"Generating response...\\n\")\n",
        "    \n",
        "    response = ask_question(question)\n",
        "    \n",
        "    print(\"Response:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(response)\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Interactive Chat Interface\n",
        "\n",
        "Chat with your documents interactively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if everything is ready\n",
        "if extracted_text is None:\n",
        "    print(\"[WARNING] Please extract text from PDFs first (see section 4)\")\n",
        "else:\n",
        "    # Chat history\n",
        "    chat_history = []\n",
        "    \n",
        "    def chat_with_documents(question: str) -> str:\n",
        "        \"\"\"Send a question to the LLM and get a response with chat history.\"\"\"\n",
        "        response = ask_question(question)\n",
        "        \n",
        "        # Store in chat history\n",
        "        chat_history.append({\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"question\": question,\n",
        "            \"response\": response\n",
        "        })\n",
        "        \n",
        "        return response\n",
        "    \n",
        "    print(\"[SUCCESS] Chat interface ready!\")\n",
        "    print(\"\\nUse chat_with_documents('your question') to ask questions.\")\n",
        "    print(\"\\nExample:\")\n",
        "    print(\"  chat_with_documents('What are the key findings?')\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Example: Ask Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Ask your first question\n",
        "if 'chat_with_documents' in globals():\n",
        "    response = chat_with_documents(\"What are the main topics in the documents?\")\n",
        "    print(response)\n",
        "else:\n",
        "    print(\"[WARNING] Please complete the setup first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. View Chat History\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display chat history as a DataFrame\n",
        "if 'chat_history' in globals() and chat_history:\n",
        "    df_history = pd.DataFrame(chat_history)\n",
        "    display(df_history)\n",
        "else:\n",
        "    print(\"No chat history yet. Start asking questions!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
