{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Document Chat Bot\n",
        "\n",
        "This notebook demonstrates a multi-document chatbot for querying PDF documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install goldmansachs.awm_genai -U\n",
        "%pip install python-dotenv pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from goldmansachs.awm_genai import DocUtils, LLM, LLMConfig\n",
        "import os\n",
        "from typing import List, Dict\n",
        "import pandas as pd\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "app_id = \"trai\"\n",
        "env = \"uat\"\n",
        "\n",
        "# Model Configuration\n",
        "model_name = \"gemini-2.0-flash\"\n",
        "temperature = 0\n",
        "log_level = \"DEBUG\"\n",
        "\n",
        "print(f\"App ID: {app_id}\")\n",
        "print(f\"Environment: {env}\")\n",
        "print(f\"Model: {model_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Document Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Document Utilities\n",
        "doc_utils = DocUtils(app_id=app_id, env=env)\n",
        "print(\"Document utilities initialized successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Upload Documents\n",
        "\n",
        "Upload multiple PDF documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define your document paths\n",
        "# Replace with your actual PDF file paths\n",
        "file_paths = [\n",
        "    \"document1.pdf\",\n",
        "    \"document2.pdf\",\n",
        "    # Add more documents as needed\n",
        "]\n",
        "\n",
        "# Upload documents\n",
        "print(\"Uploading documents...\")\n",
        "documents = doc_utils.upload(file_paths=file_paths)\n",
        "\n",
        "print(f\"\\nSuccessfully uploaded {len(documents)} documents\")\n",
        "print(\"\\nDocument Details:\")\n",
        "for i, doc in enumerate(documents, 1):\n",
        "    print(f\"{i}. {doc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialize LLM with Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define LLM configuration\n",
        "llm_config = LLMConfig(\n",
        "    app_id=app_id,\n",
        "    env=env,\n",
        "    model_name=model_name,\n",
        "    temperature=temperature,\n",
        "    log_level=log_level,\n",
        ")\n",
        "\n",
        "# Initialize LLM\n",
        "llm = LLM.init(config=llm_config)\n",
        "print(\"LLM initialized successfully\")\n",
        "print(f\"Model: {model_name}\")\n",
        "print(f\"Temperature: {temperature}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Query Documents - Single Question\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ask a question about the documents\n",
        "question = \"Write a summary about AUS in Alternatives for the companies.\"\n",
        "\n",
        "print(f\"Question: {question}\\n\")\n",
        "print(\"Generating response...\\n\")\n",
        "\n",
        "response = llm.invoke(\n",
        "    question,\n",
        "    documents=documents,\n",
        ")\n",
        "\n",
        "print(\"Response:\")\n",
        "print(\"-\" * 80)\n",
        "print(response)\n",
        "print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Interactive Chat Interface\n",
        "\n",
        "Chat with your documents interactively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chat history\n",
        "chat_history = []\n",
        "\n",
        "def chat_with_documents(question: str) -> str:\n",
        "    \"\"\"Send a question to the LLM and get a response.\"\"\"\n",
        "    response = llm.invoke(\n",
        "        question,\n",
        "        documents=documents,\n",
        "    )\n",
        "    \n",
        "    # Store in chat history\n",
        "    chat_history.append({\n",
        "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"question\": question,\n",
        "        \"response\": response\n",
        "    })\n",
        "    \n",
        "    return response\n",
        "\n",
        "print(\"Chat interface ready. Use chat_with_documents('your question') to ask questions.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
